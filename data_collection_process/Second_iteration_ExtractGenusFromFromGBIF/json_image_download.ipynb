{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m# Load the JSON data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mall_data_colombia.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m---> 30\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n\u001b[0;32m     32\u001b[0m \u001b[39m# Assuming the root of the JSON is a list of records\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data_to_process \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\json\\decoder.py:338\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_decode(s, idx\u001b[39m=\u001b[39m_w(s, \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mend())\n\u001b[1;32m--> 338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[0;32m    340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_image(genus_dir, media, record, metadata):\n",
    "    image_url = media.get('identifier')\n",
    "    if image_url:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            image_name = os.path.basename(image_url.split('/')[-1]) + \".jpg\"  # Extract the image name from the URL\n",
    "            image_path = os.path.join(genus_dir, image_name)\n",
    "            with open(image_path, 'wb') as img_file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    img_file.write(chunk)\n",
    "            \n",
    "            # Add entry to metadata\n",
    "            metadata[image_name] = {\n",
    "                \"family\": record.get('family', \"\"),\n",
    "                \"genus\": record.get('genus', \"\"),\n",
    "                \"species\": record.get('species', \"\"),\n",
    "                \"order\": record.get('order', \"\"),\n",
    "                \"phylum\": record.get('phylum', \"\"),\n",
    "                \"class\": record.get('class', \"\"),\n",
    "                \"kingdom\": record.get('kingdom', \"\")\n",
    "            }\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"all_data_colombia.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assuming the root of the JSON is a list of records\n",
    "data_to_process = data\n",
    "\n",
    "# Create a root directory for all images if it doesn't exist\n",
    "if not os.path.exists('fungi_images'):\n",
    "    os.mkdir('fungi_images')\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel downloads\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Iterate over each record in the data\n",
    "    for record in data_to_process:\n",
    "        genus_name = record.get('genus', \"unknown_genus\").replace(\" \", \"_\")  # Replace spaces with underscores\n",
    "        media_entries = record.get('media', [])\n",
    "        \n",
    "        # Create a directory for the genus if it doesn't exist\n",
    "        genus_dir = os.path.join('fungi_images', genus_name)\n",
    "        if not os.path.exists(genus_dir):\n",
    "            os.mkdir(genus_dir)\n",
    "        \n",
    "        # Metadata dictionary for the genus\n",
    "        metadata = {}\n",
    "        \n",
    "        # Parallel download of images\n",
    "        futures = [executor.submit(download_image, genus_dir, media, record, metadata) for media in media_entries]\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "        \n",
    "        # Save metadata to JSON file\n",
    "        with open(os.path.join(genus_dir, \"metadata.json\"), \"w\") as meta_file:\n",
    "            json.dump(metadata, meta_file, indent=4)\n",
    "\n",
    "print(\"Images downloaded and metadata files created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
