{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genus: Lachnum\n",
      "Waiting for 3.12 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 3.33 seconds before the next request...\n",
      "Waiting for 3.18 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 4.00 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 6.63 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 6.54 seconds before the next request...\n",
      "Waiting for 3.27 seconds before the next request...\n",
      "Downloading images for Lachnum varians...\n",
      "Waiting for 5.24 seconds before the next request...\n",
      "Waiting for 6.23 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 5.77 seconds before the next request...\n",
      "Waiting for 3.58 seconds before the next request...\n",
      "Waiting for 6.09 seconds before the next request...\n",
      "Waiting for 3.82 seconds before the next request...\n",
      "Waiting for 5.20 seconds before the next request...\n",
      "Waiting for 6.17 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 5.56 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 6.45 seconds before the next request...\n",
      "Waiting for 3.85 seconds before the next request...\n",
      "Waiting for 4.78 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 5.23 seconds before the next request...\n",
      "Waiting for 5.04 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 4.10 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 5.92 seconds before the next request...\n",
      "Waiting for 3.16 seconds before the next request...\n",
      "Waiting for 6.94 seconds before the next request...\n",
      "Waiting for 6.12 seconds before the next request...\n",
      "Waiting for 4.30 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 4.29 seconds before the next request...\n",
      "Waiting for 4.59 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 3.37 seconds before the next request...\n",
      "Downloading images for Lachnum varians...\n",
      "Waiting for 4.73 seconds before the next request...\n",
      "Waiting for 4.45 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 6.29 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 6.31 seconds before the next request...\n",
      "Waiting for 5.97 seconds before the next request...\n",
      "Waiting for 3.31 seconds before the next request...\n",
      "Waiting for 6.64 seconds before the next request...\n",
      "Waiting for 4.02 seconds before the next request...\n",
      "Waiting for 3.28 seconds before the next request...\n",
      "Waiting for 6.98 seconds before the next request...\n",
      "Downloading images for Lachnum...\n",
      "Waiting for 3.33 seconds before the next request...\n",
      "Waiting for 5.15 seconds before the next request...\n",
      "Waiting for 4.36 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 3.77 seconds before the next request...\n",
      "Downloading images for Lachnum lachnoderma...\n",
      "Waiting for 4.93 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 5.58 seconds before the next request...\n",
      "Waiting for 5.14 seconds before the next request...\n",
      "Waiting for 4.59 seconds before the next request...\n",
      "Downloading images for Lachnum virgineum...\n",
      "Waiting for 4.16 seconds before the next request...\n",
      "Waiting for 5.43 seconds before the next request...\n",
      "Processing genus: Phallus\n",
      "Downloading images for Phallus ravenelii...\n",
      "Waiting for 6.47 seconds before the next request...\n",
      "Downloading images for Phallus...\n",
      "Waiting for 6.25 seconds before the next request...\n",
      "Waiting for 5.96 seconds before the next request...\n",
      "Downloading images for Phallus indusiatus...\n",
      "Waiting for 3.76 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 4.93 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 5.12 seconds before the next request...\n",
      "Waiting for 6.71 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 5.29 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 6.86 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 4.77 seconds before the next request...\n",
      "Waiting for 6.88 seconds before the next request...\n",
      "Waiting for 5.74 seconds before the next request...\n",
      "Downloading images for Phallus ravenelii...\n",
      "Waiting for 6.36 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 3.76 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 6.38 seconds before the next request...\n",
      "Waiting for 5.81 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 3.77 seconds before the next request...\n",
      "Downloading images for Phallus indusiatus...\n",
      "Waiting for 4.03 seconds before the next request...\n",
      "Downloading images for Phallus indusiatus...\n",
      "Waiting for 3.68 seconds before the next request...\n",
      "Downloading images for Phallus multicolor...\n",
      "Waiting for 6.13 seconds before the next request...\n",
      "Waiting for 3.59 seconds before the next request...\n",
      "Downloading images for Phallus hadriani...\n",
      "Waiting for 4.56 seconds before the next request...\n",
      "Waiting for 3.64 seconds before the next request...\n",
      "Downloading images for Phallus hadriani...\n",
      "Waiting for 3.01 seconds before the next request...\n",
      "Waiting for 3.75 seconds before the next request...\n",
      "Waiting for 6.47 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 6.91 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 4.63 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 4.72 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 4.31 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 3.16 seconds before the next request...\n",
      "Waiting for 5.51 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 6.58 seconds before the next request...\n",
      "Waiting for 3.00 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 6.55 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 6.35 seconds before the next request...\n",
      "Waiting for 4.49 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 6.88 seconds before the next request...\n",
      "Downloading images for Phallus impudicus...\n",
      "Waiting for 4.24 seconds before the next request...\n",
      "Waiting for 5.86 seconds before the next request...\n",
      "Waiting for 4.47 seconds before the next request...\n",
      "Waiting for 3.23 seconds before the next request...\n",
      "Downloading images for Phallus indusiatus...\n",
      "Waiting for 4.06 seconds before the next request...\n",
      "Downloading images for Phallus...\n",
      "Waiting for 4.48 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 5.60 seconds before the next request...\n",
      "Downloading images for Phallus...\n",
      "Waiting for 5.95 seconds before the next request...\n",
      "Downloading images for Phallus luteus...\n",
      "Waiting for 6.75 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 4.25 seconds before the next request...\n",
      "Downloading images for Phallus rugulosus...\n",
      "Waiting for 4.29 seconds before the next request...\n",
      "Waiting for 4.17 seconds before the next request...\n",
      "Processing genus: Orbilia\n",
      "Waiting for 4.77 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.39 seconds before the next request...\n",
      "Waiting for 4.17 seconds before the next request...\n",
      "Waiting for 5.76 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.05 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.81 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.13 seconds before the next request...\n",
      "Waiting for 5.22 seconds before the next request...\n",
      "Waiting for 5.20 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.79 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.21 seconds before the next request...\n",
      "Waiting for 4.47 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.19 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 6.60 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.12 seconds before the next request...\n",
      "Waiting for 5.79 seconds before the next request...\n",
      "Waiting for 6.04 seconds before the next request...\n",
      "Downloading images for Orbilia xanthostigma...\n",
      "Waiting for 3.58 seconds before the next request...\n",
      "Waiting for 4.23 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.11 seconds before the next request...\n",
      "Waiting for 5.96 seconds before the next request...\n",
      "Waiting for 5.22 seconds before the next request...\n",
      "Waiting for 4.31 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.24 seconds before the next request...\n",
      "Downloading images for Orbilia xanthostigma...\n",
      "Waiting for 6.91 seconds before the next request...\n",
      "Downloading images for Orbilia xanthostigma...\n",
      "Waiting for 5.62 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.33 seconds before the next request...\n",
      "Waiting for 3.50 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 6.74 seconds before the next request...\n",
      "Waiting for 6.10 seconds before the next request...\n",
      "Waiting for 6.96 seconds before the next request...\n",
      "Waiting for 5.86 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.11 seconds before the next request...\n",
      "Waiting for 6.98 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.05 seconds before the next request...\n",
      "Downloading images for Orbilia xanthostigma...\n",
      "Waiting for 6.47 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 6.26 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.33 seconds before the next request...\n",
      "Waiting for 4.19 seconds before the next request...\n",
      "Waiting for 5.39 seconds before the next request...\n",
      "Waiting for 4.04 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 6.86 seconds before the next request...\n",
      "Waiting for 6.89 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.43 seconds before the next request...\n",
      "Waiting for 6.47 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 3.08 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.88 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.16 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 5.79 seconds before the next request...\n",
      "Downloading images for Orbilia...\n",
      "Waiting for 4.78 seconds before the next request...\n",
      "Processing genus: Stictis\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 6.77 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.34 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 6.66 seconds before the next request...\n",
      "Downloading images for Stictis urceolata...\n",
      "Waiting for 4.96 seconds before the next request...\n",
      "Waiting for 5.71 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.02 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.81 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.71 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.68 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 6.78 seconds before the next request...\n",
      "Waiting for 4.93 seconds before the next request...\n",
      "Waiting for 4.02 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.09 seconds before the next request...\n",
      "Waiting for 4.23 seconds before the next request...\n",
      "Waiting for 4.27 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.23 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.38 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.36 seconds before the next request...\n",
      "Waiting for 5.57 seconds before the next request...\n",
      "Waiting for 5.10 seconds before the next request...\n",
      "Downloading images for Stictis urceolata...\n",
      "Waiting for 6.55 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.35 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.53 seconds before the next request...\n",
      "Waiting for 6.01 seconds before the next request...\n",
      "Waiting for 5.50 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.60 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 6.36 seconds before the next request...\n",
      "Waiting for 6.62 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.14 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 5.65 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 3.45 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 6.05 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 3.56 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 4.84 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 5.42 seconds before the next request...\n",
      "Waiting for 3.23 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 6.08 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 6.96 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 4.90 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 6.89 seconds before the next request...\n",
      "Downloading images for Stictis radiata...\n",
      "Waiting for 4.00 seconds before the next request...\n",
      "Downloading images for Stictis...\n",
      "Waiting for 5.62 seconds before the next request...\n",
      "Downloading images for Stictis urceolata...\n",
      "Waiting for 4.17 seconds before the next request...\n",
      "Waiting for 6.22 seconds before the next request...\n"
     ]
    },
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='api.inaturalist.org', port=443): Max retries exceeded with url: /v1/observations/163519245?include_new_projects=true&preferred_place_id=&locale=en&ttl=-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39mserver_hostname\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39mserver_hostname)\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msslsocket_class\u001b[39m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[39m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[39m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[39m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[39m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1075\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_handshake()\n\u001b[0;32m   1076\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mdo_handshake()\n\u001b[0;32m   1347\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:1002)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39me, _pool\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, _stacktrace\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.inaturalist.org', port=443): Max retries exceeded with url: /v1/observations/163519245?include_new_projects=true&preferred_place_id=&locale=en&ttl=-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m# Process each genus in the tags.json file\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mfor\u001b[39;00m genus, details \u001b[39min\u001b[39;00m tags\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 133\u001b[0m     process_genus(genus, details)\n\u001b[0;32m    134\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m, in \u001b[0;36mprocess_genus\u001b[1;34m(name, details)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39m# Fetch and download images for each observation ID\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m observation_id \u001b[39min\u001b[39;00m ids:\n\u001b[1;32m---> 64\u001b[0m     image_urls, observation_name \u001b[39m=\u001b[39m get_observation_images(observation_id, name)\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m image_urls:\n\u001b[0;32m     66\u001b[0m         download_images(image_urls, name, \u001b[39mstr\u001b[39m(observation_id), observation_name)\n",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m, in \u001b[0;36mget_observation_images\u001b[1;34m(observation_id, name)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_observation_images\u001b[39m(observation_id, name):\n\u001b[0;32m     76\u001b[0m     \u001b[39m# Make the request to the observation endpoint\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     endpoint \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.inaturalist.org/v1/observations/\u001b[39m\u001b[39m{\u001b[39;00mobservation_id\u001b[39m}\u001b[39;00m\u001b[39m?include_new_projects=true&preferred_place_id=&locale=en&ttl=-1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 78\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(endpoint)\n\u001b[0;32m     79\u001b[0m     data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[0;32m     81\u001b[0m     observation_photos \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m, [{}])[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mobservation_photos\u001b[39m\u001b[39m'\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\newHope\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:517\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='api.inaturalist.org', port=443): Max retries exceeded with url: /v1/observations/163519245?include_new_projects=true&preferred_place_id=&locale=en&ttl=-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))"
     ]
    }
   ],
   "source": [
    "## Final code to download\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "def write_metadata_to_folder(genus, details, parent_folder):\n",
    "    \"\"\"\n",
    "    Write the metadata for a given genus to a metadata.json file inside the specified folder.\n",
    "    \"\"\"\n",
    "    metadata = {genus: details}\n",
    "    metadata_path = os.path.join(parent_folder, 'metadata.json')\n",
    "    with open(metadata_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "def make_request_with_backoff(url, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except (requests.HTTPError, requests.ConnectionError) as e:\n",
    "            print(f\"Error making request to {url}. Error: {e}\")\n",
    "            if attempt < max_retries - 1:  # i.e. if it's not the last attempt\n",
    "                wait_time = (2 ** attempt) + (random.randint(0, 1000) / 1000)\n",
    "                print(f\"Waiting for {wait_time:.2f} seconds before retrying...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(\"Max retries reached. Moving on...\")\n",
    "                return None\n",
    "\n",
    "def process_genus(name, details):\n",
    "    print(f\"Processing genus: {name}\")\n",
    "    \n",
    "    # Define the API endpoint for fetching parent ID\n",
    "    endpoint = f\"https://api.inaturalist.org/v1/taxa/autocomplete?q={name}&per_page=50&locale=en&preferred_place_id=\"\n",
    "    response = make_request_with_backoff(endpoint)\n",
    "    if not response:\n",
    "        return\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the parent_id for the genus\n",
    "    parent_id = None\n",
    "    for result in data['results']:\n",
    "        if result['name'] == name:\n",
    "            parent_id = result['parent_id']\n",
    "            break\n",
    "\n",
    "    # Define the API endpoint for fetching observations using the parent ID\n",
    "    endpoint = f\"https://api.inaturalist.org/v1/observations?verifiable=true&order_by=observations.id&order=desc&page=1&spam=false&taxon_id={parent_id}&locale=en&per_page=50\"\n",
    "    response = make_request_with_backoff(endpoint)\n",
    "    if not response:\n",
    "        return\n",
    "    observations_data = response.json()\n",
    "\n",
    "    # Extract the IDs from the observations data\n",
    "    ids = [observation['id'] for observation in observations_data['results']]\n",
    "\n",
    "    # Fetch and download images for each observation ID\n",
    "    for observation_id in ids:\n",
    "        image_urls, observation_name = get_observation_images(observation_id, name)\n",
    "        if image_urls:\n",
    "            download_images(image_urls, name, str(observation_id), observation_name)\n",
    "        delay = random.uniform(3, 7)  # Random delay between 3 to 7 seconds\n",
    "        print(f\"Waiting for {delay:.2f} seconds before the next request...\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    # After downloading images, write the metadata to the folder\n",
    "    genus_folder_path = os.path.join(\"fungi_images\", name)\n",
    "    write_metadata_to_folder(name, details, genus_folder_path)\n",
    "\n",
    "def get_observation_images(observation_id, name):\n",
    "    # Make the request to the observation endpoint\n",
    "    endpoint = f\"https://api.inaturalist.org/v1/observations/{observation_id}?include_new_projects=true&preferred_place_id=&locale=en&ttl=-1\"\n",
    "    response = requests.get(endpoint)\n",
    "    data = response.json()\n",
    "\n",
    "    observation_photos = data.get('results', [{}])[0].get('observation_photos', [])\n",
    "    \n",
    "    # If observation_photos is empty, try to get the default_photo\n",
    "    if not observation_photos:\n",
    "        default_photo = data.get('results', [{}])[0].get('taxon', {}).get('default_photo', {})\n",
    "        if default_photo:\n",
    "            square_url = default_photo.get('square_url', '')\n",
    "            medium_url = default_photo.get('medium_url', '')\n",
    "            observation_photos = [{'photo': {'url': square_url}}, {'photo': {'url': medium_url}}]\n",
    "\n",
    "    # Extract the image URLs and replace with 'large.jpeg' or 'medium.jpeg'\n",
    "    image_urls = []\n",
    "    for photo in observation_photos:\n",
    "        base_url = photo.get('photo', {}).get('url', '')\n",
    "        large_url = base_url.replace('square.jpeg', 'large.jpeg')\n",
    "        medium_url = base_url.replace('square.jpeg', 'medium.jpeg')\n",
    "        image_urls.extend([large_url, medium_url])\n",
    "    \n",
    "    observation_name = data.get('results', [{}])[0].get('taxon', {}).get('name', '')\n",
    "\n",
    "    # Use a regular expression to match the desired pattern\n",
    "    if not re.match(r'^\\b' + re.escape(name) + r'\\b( \\b\\w+\\b)?$', observation_name):\n",
    "        return [], observation_name\n",
    "\n",
    "    return image_urls, observation_name\n",
    "\n",
    "\n",
    "def download_images(image_urls, parent_folder, subfolder_name, observation_name):\n",
    "    print(f\"Downloading images for {observation_name}...\")\n",
    "    \n",
    "    parent_folder = os.path.join(\"fungi_images\", parent_folder)\n",
    "    # Create a parent directory with the 'name' variable if it doesn't exist\n",
    "    if not os.path.exists(parent_folder):\n",
    "        os.makedirs(parent_folder)\n",
    "    \n",
    "    # Create a subdirectory for the observation ID inside the parent directory\n",
    "    full_path = os.path.join(parent_folder, subfolder_name)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "\n",
    "    for i, img_url in enumerate(image_urls):\n",
    "        response = requests.get(img_url)\n",
    "        file_name = os.path.join(full_path, f\"{observation_name}_{i + 1}.jpeg\")\n",
    "        with open(file_name, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "# Load the tags.json file\n",
    "with open('tags.json', 'r') as file:\n",
    "    tags = json.load(file)\n",
    "\n",
    "# Process each genus in the tags.json file\n",
    "for genus, details in tags.items():\n",
    "    process_genus(genus, details)\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
